---
body: ''
content_type: resource
draft: false
file: /courses/18-s096-matrix-calculus-for-machine-learning-and-beyond-january-iap-2023/ocw_18s096_lecture05-part1-new_2023jan27_360p_16_9.mp4
file_size: 43928176
file_type: video/mp4
image_metadata:
  caption: ''
  credit: ''
  image-alt: ''
learning_resource_types:
- Lecture Videos
license: https://creativecommons.org/licenses/by-nc-sa/4.0/
resourcetype: Video
title: 'Lecture 5 Part 1: Derivative of Matrix Determinant and Inverse'
uid: 12a43af7-fef7-43ce-8263-3303c3b06d11
video_files:
  archive_url: ''
  video_captions_file: /courses/18-s096-matrix-calculus-for-machine-learning-and-beyond-january-iap-2023/ocw_18s096_lecture05-part1-new_2023jan27_captions.vtt
  video_thumbnail_file: https://img.youtube.com/vi/66Hc7vnDQ8o/default.jpg
  video_transcript_file: /courses/18-s096-matrix-calculus-for-machine-learning-and-beyond-january-iap-2023/ocw_18s096_lecture05-part1-new_2023jan27_transcript.pdf
video_metadata:
  video_speakers: ''
  video_tags: matrix gradient, determinant function, adjugate matrix, Jacobian, matrix
    inverse
  youtube_description: "MIT 18.S096 Matrix Calculus For Machine Learning And Beyond,\
    \ IAP 2023\nInstructors: Alan Edelman, Steven G. Johnson\n\nView the complete\
    \ course: https://ocw.mit.edu/courses/18-s096-matrix-calculus-for-machine-learning-and-beyond-january-iap-2023/\n\
    YouTube Playlist: https://www.youtube.com/playlist?list=PLUl4u3cNGP62EaLLH92E_VCN4izBKK6OE\n\
    \nDescription: The first ~6 minutes are on the topic Norms and Derivatives: Why\
    \ a norm of the input and output are needed to define a derivative.  Now we can\
    \ find the \u201Cmatrix gradient\u201D of the determinant function (leading to\
    \ the \u201Cadjugate\u201D matrix), and the \u201CJacobian\u201D of a matrix inverse.\n\
    \nLicense: Creative Commons BY-NC-SA\nMore information at https://ocw.mit.edu/terms\n\
    More courses at https://ocw.mit.edu\nSupport OCW at http://ow.ly/a1If50zVRlQ\n\
    \nWe encourage constructive comments and discussion on OCW\u2019s YouTube and\
    \ other social media channels. Personal attacks, hate speech, trolling, and inappropriate\
    \ comments are not allowed and may be removed. More details at https://ocw.mit.edu/comments."
  youtube_id: 66Hc7vnDQ8o
---
**Description:** The first ~6 minutes are on the topic Norms and Derivatives: Why a norm of the input and output are needed to define a derivative.  Now we can find the “matrix gradient” of the determinant function (leading to the “adjugate” matrix), and the “Jacobian” of a matrix inverse.

**Instructors:** Alan Edelman, Steven G. Johnson