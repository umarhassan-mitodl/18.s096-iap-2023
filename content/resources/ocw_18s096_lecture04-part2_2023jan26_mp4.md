---
body: ''
content_type: resource
draft: false
file: /courses/18-s096-matrix-calculus-for-machine-learning-and-beyond-january-iap-2023/ocw_18s096_lecture04-part2_2023jan26_360p_16_9.mp4
file_size: 94860812
file_type: video/mp4
image_metadata:
  caption: ''
  credit: ''
  image-alt: ''
learning_resource_types:
- Lecture Videos
license: https://creativecommons.org/licenses/by-nc-sa/4.0/
resourcetype: Video
title: 'Lecture 4 Part 2: Nonlinear Root Finding, Optimization, and Adjoint Gradient
  Methods'
uid: 40956322-eb8c-4e1d-8f21-d2e60888f142
video_files:
  archive_url: ''
  video_captions_file: /courses/18-s096-matrix-calculus-for-machine-learning-and-beyond-january-iap-2023/1A065H99Yhsv0hU1C-wFftrck9xfhs31f_transcript.webvtt
  video_thumbnail_file: https://img.youtube.com/vi/lBfqvBJaFmc/default.jpg
  video_transcript_file: /courses/18-s096-matrix-calculus-for-machine-learning-and-beyond-january-iap-2023/1A065H99Yhsv0hU1C-wFftrck9xfhs31f_transcript.pdf
video_metadata:
  video_speakers: ''
  video_tags: "Newton\u2019s method, optimization, gradient descent, adjoint methods"
  youtube_description: "MIT 18.S096 Matrix Calculus For Machine Learning And Beyond,\
    \ IAP 2023\nInstructors: Alan Edelman, Steven G. Johnson\n\nView the complete\
    \ course: https://ocw.mit.edu/courses/18-s096-matrix-calculus-for-machine-learning-and-beyond-january-iap-2023/\n\
    YouTube Playlist: https://www.youtube.com/playlist?list=PLUl4u3cNGP62EaLLH92E_VCN4izBKK6OE\n\
    \nDescription: Nonlinear root finding by Newton\u2019s method and optimization\
    \ by gradient descent. \u201CAdjoint\u201D methods (reverse-mode/backpropagation)\
    \ lets us find gradients efficiently for large-scale engineering optimization.\n\
    \nLicense: Creative Commons BY-NC-SA\nMore information at https://ocw.mit.edu/terms\n\
    More courses at https://ocw.mit.edu\nSupport OCW at http://ow.ly/a1If50zVRlQ\n\
    \nWe encourage constructive comments and discussion on OCW\u2019s YouTube and\
    \ other social media channels. Personal attacks, hate speech, trolling, and inappropriate\
    \ comments are not allowed and may be removed. More details at https://ocw.mit.edu/comments."
  youtube_id: lBfqvBJaFmc
---
**Description:** Nonlinear root finding by Newton’s method and optimization by gradient descent. “Adjoint” methods (reverse-mode/backpropagation) let us find gradients efficiently for large-scale engineering optimization.

**Instructors:** Alan Edelman, Steven G. Johnson